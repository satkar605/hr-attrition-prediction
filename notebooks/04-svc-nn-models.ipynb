{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c9fa3b",
   "metadata": {},
   "source": [
    "# SVC and Neural Network Models: Margin-Based and Deep Learning Approaches\n",
    "\n",
    "This notebook implements two advanced models with GridSearchCV hyperparameter tuning:\n",
    "1. **SVC (RBF Kernel)** - Margin-based classifier with non-linear decision boundary\n",
    "2. **MLPClassifier** - Feedforward neural network for tabular classification\n",
    "\n",
    "Each model is trained and evaluated on three datasets:\n",
    "- **Raw/Original** dataset (imbalanced)\n",
    "- **SMOTE Balanced** dataset (synthetic oversampling)\n",
    "- **ADASYN Balanced** dataset (adaptive synthetic oversampling)\n",
    "\n",
    "**Approach:**\n",
    "- GridSearchCV with f1 or roc_auc scoring (appropriate for imbalanced classification)\n",
    "- Centralized metrics storage for all model-dataset combinations\n",
    "- Storage of predicted probabilities for ROC curve plotting (Task 5)\n",
    "- Best hyperparameter storage for each model-dataset combination\n",
    "\n",
    "**Prerequisites:** Run notebook 01 (data exploration) first to generate the processed data files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ae5c0c",
   "metadata": {},
   "source": [
    "## Step 1: Load Processed Data from Notebook 01\n",
    "\n",
    "The following cell loads the pre-processed and scaled dataframe from notebook 01. This ensures we're working with the same processed data without re-running all data cleaning and feature engineering steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43a0c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PROCESSED DATA LOADED SUCCESSFULLY\n",
      "======================================================================\n",
      " Loaded from: ../data/processed/df_scaled.pkl\n",
      " DataFrame shape: (1470, 29)\n",
      " Columns: 29\n",
      " Rows: 1470\n",
      "\n",
      "First few columns: ['Attrition', 'DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobSatisfaction', 'NumCompaniesWorked', 'OverTime', 'PercentSalaryHike']\n",
      "\n",
      "Attrition distribution:\n",
      "Attrition\n",
      "0    1233\n",
      "1     237\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Data ready for modeling!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Load Processed Data from Notebook 01\n",
    "# ============================================================\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Check if processed data exists\n",
    "data_dir = \"../data/processed\"\n",
    "pkl_path = f\"{data_dir}/df_scaled.pkl\"\n",
    "\n",
    "if os.path.exists(pkl_path):\n",
    "    # Load the processed dataframe\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        df_scaled = pickle.load(f)\n",
    "    \n",
    "    # Load the scaler (if needed for future transformations)\n",
    "    scaler_path = f\"{data_dir}/scaler.pkl\"\n",
    "    if os.path.exists(scaler_path):\n",
    "        with open(scaler_path, \"rb\") as f:\n",
    "            scaler = pickle.load(f)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"PROCESSED DATA LOADED SUCCESSFULLY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\" Loaded from: {pkl_path}\")\n",
    "    print(f\" DataFrame shape: {df_scaled.shape}\")\n",
    "    print(f\" Columns: {df_scaled.shape[1]}\")\n",
    "    print(f\" Rows: {df_scaled.shape[0]}\")\n",
    "    print(f\"\\nFirst few columns: {list(df_scaled.columns[:10])}\")\n",
    "    print(f\"\\nAttrition distribution:\")\n",
    "    print(df_scaled[\"Attrition\"].value_counts())\n",
    "    print(f\"\\n Data ready for modeling!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        f\"\\n{'='*70}\\n\"\n",
    "        f\"PROCESSED DATA NOT FOUND\\n\"\n",
    "        f\"{'='*70}\\n\"\n",
    "        f\"File not found: {pkl_path}\\n\\n\"\n",
    "        f\"Please run notebook 01 (01-data-exploration.ipynb) first:\\n\"\n",
    "        f\"1. Execute all cells in notebook 01\\n\"\n",
    "        f\"2. This will save the processed data to {data_dir}/\\n\"\n",
    "        f\"3. Then return to this notebook\\n\"\n",
    "        f\"{'='*70}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e2443",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Three Datasets (Raw, SMOTE, ADASYN)\n",
    "\n",
    "Prepare the three response variable sets for model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7edf7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAIN-TEST SPLIT COMPLETE\n",
      "======================================================================\n",
      "Training set shape: (1176, 28)\n",
      "Test set shape: (294, 28)\n",
      "\n",
      "Training set Attrition distribution:\n",
      "Attrition\n",
      "0    986\n",
      "1    190\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set Attrition distribution:\n",
      "Attrition\n",
      "0    247\n",
      "1     47\n",
      "Name: count, dtype: int64\n",
      "======================================================================\n",
      "\n",
      "Applying SMOTE...\n",
      "SMOTE dataset shape: (1972, 28)\n",
      "SMOTE Attrition distribution:\n",
      "Attrition\n",
      "0    986\n",
      "1    986\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Applying ADASYN...\n",
      "ADASYN dataset shape: (1911, 28)\n",
      "ADASYN Attrition distribution:\n",
      "Attrition\n",
      "0    986\n",
      "1    925\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "THREE DATASETS PREPARED SUCCESSFULLY\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satkarkarki/Desktop/portfolio/hr-attrition/.venv/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/Users/satkarkarki/Desktop/portfolio/hr-attrition/.venv/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Prepare Three Datasets: Raw, SMOTE, ADASYN\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# Separate features and target\n",
    "X = df_scaled.drop(columns=[\"Attrition\"])\n",
    "y = df_scaled[\"Attrition\"]\n",
    "\n",
    "# Train-test split (80-20) with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAIN-TEST SPLIT COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"\\nTraining set Attrition distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest set Attrition distribution:\")\n",
    "print(y_test.value_counts())\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Prepare three datasets\n",
    "training_sets = {}\n",
    "\n",
    "# 1. Raw/Original dataset (imbalanced)\n",
    "training_sets['raw'] = {\n",
    "    'name': 'Raw/Original',\n",
    "    'description': 'Original imbalanced dataset',\n",
    "    'X_train': X_train,\n",
    "    'y_train': y_train\n",
    "}\n",
    "\n",
    "# 2. SMOTE balanced dataset\n",
    "print(\"\\nApplying SMOTE...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "training_sets['smote'] = {\n",
    "    'name': 'SMOTE Balanced',\n",
    "    'description': 'SMOTE synthetic oversampling',\n",
    "    'X_train': X_train_smote,\n",
    "    'y_train': y_train_smote\n",
    "}\n",
    "print(f\"SMOTE dataset shape: {X_train_smote.shape}\")\n",
    "print(f\"SMOTE Attrition distribution:\\n{pd.Series(y_train_smote).value_counts()}\")\n",
    "\n",
    "# 3. ADASYN balanced dataset\n",
    "print(\"\\nApplying ADASYN...\")\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "training_sets['adasyn'] = {\n",
    "    'name': 'ADASYN Balanced',\n",
    "    'description': 'ADASYN adaptive synthetic oversampling',\n",
    "    'X_train': X_train_adasyn,\n",
    "    'y_train': y_train_adasyn\n",
    "}\n",
    "print(f\"ADASYN dataset shape: {X_train_adasyn.shape}\")\n",
    "print(f\"ADASYN Attrition distribution:\\n{pd.Series(y_train_adasyn).value_counts()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"THREE DATASETS PREPARED SUCCESSFULLY\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a73aa0",
   "metadata": {},
   "source": [
    "## Step 3: Imports and Extended Evaluation Function\n",
    "\n",
    "Import required libraries and create an extended evaluation function that includes confusion matrix components (tn, fp, fn, tp).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc746020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Imports and Extended Evaluation Function\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inspect\n",
    "\n",
    "def evaluate_model(y_test, y_pred, y_prob):\n",
    "    \"\"\"\n",
    "    Calculate all required evaluation metrics including confusion matrix components.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_test : array-like\n",
    "        True labels\n",
    "    y_pred : array-like\n",
    "        Predicted labels\n",
    "    y_prob : array-like\n",
    "        Predicted probabilities for positive class\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing all metrics and confusion matrix components\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_prob),\n",
    "        'confusion_matrix': cm,\n",
    "        'tn': int(tn),\n",
    "        'fp': int(fp),\n",
    "        'fn': int(fn),\n",
    "        'tp': int(tp)\n",
    "    }\n",
    "\n",
    "\n",
    "def train_model_with_gridsearch(model_class, param_grid, X_train, y_train, X_test, y_test,\n",
    "                                model_name, dataset_name, **model_kwargs):\n",
    "    \"\"\"\n",
    "    Unified function to train any model with GridSearchCV.\n",
    "    Stores predicted probabilities for ROC curves.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_class : class\n",
    "        Model class to instantiate\n",
    "    param_grid : dict\n",
    "        Hyperparameter grid for GridSearchCV\n",
    "    X_train : DataFrame/array\n",
    "        Training features\n",
    "    y_train : Series/array\n",
    "        Training labels\n",
    "    X_test : DataFrame/array\n",
    "        Test features\n",
    "    y_test : Series/array\n",
    "        Test labels\n",
    "    model_name : str\n",
    "        Name of the model (e.g., 'SVC', 'MLP')\n",
    "    dataset_name : str\n",
    "        Name of the dataset (e.g., 'raw', 'smote', 'adasyn')\n",
    "    **model_kwargs : dict\n",
    "        Additional keyword arguments for model initialization\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing best estimator, metrics, and best parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if model accepts random_state parameter\n",
    "    sig = inspect.signature(model_class.__init__)\n",
    "    accepts_random_state = 'random_state' in sig.parameters\n",
    "    \n",
    "    # Build initialization parameters\n",
    "    init_params = {}\n",
    "    if accepts_random_state and 'random_state' not in model_kwargs:\n",
    "        init_params['random_state'] = 42\n",
    "    \n",
    "    # Add any additional kwargs (these will override defaults if they conflict)\n",
    "    init_params.update(model_kwargs)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = model_class(**init_params)\n",
    "    \n",
    "    # GridSearchCV with f1 scoring (balanced metric for imbalanced data)\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='f1',  # Use f1 for balanced optimization\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"  Running GridSearchCV for {model_name} on {dataset_name} dataset...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get best estimator\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_test_pred = best_estimator.predict(X_test)\n",
    "    y_test_prob = best_estimator.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = evaluate_model(y_test, y_test_pred, y_test_prob)\n",
    "    \n",
    "    print(f\"  Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"  Test Metrics - Accuracy: {metrics['accuracy']:.4f}, Precision: {metrics['precision']:.4f}, \"\n",
    "          f\"Recall: {metrics['recall']:.4f}, F1: {metrics['f1']:.4f}, ROC-AUC: {metrics['roc_auc']:.4f}\")\n",
    "    print(f\"  Confusion Matrix - TN: {metrics['tn']}, FP: {metrics['fp']}, FN: {metrics['fn']}, TP: {metrics['tp']}\")\n",
    "    \n",
    "    return {\n",
    "        'best_estimator': best_estimator,\n",
    "        'metrics': metrics,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'y_test': y_test,\n",
    "        'y_test_prob': y_test_prob\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ddce48",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9039fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXTENDED STORAGE INITIALIZED\n",
      "======================================================================\n",
      "Storage structures ready for:\n",
      "  - Centralized metrics table\n",
      "  - ROC probabilities (for Task 5)\n",
      "  - Best hyperparameters\n",
      "  - Best estimators\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Initialize Extended Storage\n",
    "# ============================================================\n",
    "\n",
    "# Centralized metrics storage\n",
    "# Each entry will have: model_name, dataset_type, accuracy, precision, recall, f1, roc_auc, tn, fp, fn, tp\n",
    "all_metrics = []\n",
    "\n",
    "# ROC probabilities storage for Task 5\n",
    "# Structure: {model_name: {dataset_type: {'y_true': array, 'y_score': array}}}\n",
    "roc_probabilities = {\n",
    "    'SVC': {},\n",
    "    'MLP': {}\n",
    "}\n",
    "\n",
    "# Best hyperparameters storage\n",
    "# Structure: {model_name: {dataset_type: best_params_dict}}\n",
    "best_hyperparameters = {\n",
    "    'SVC': {},\n",
    "    'MLP': {}\n",
    "}\n",
    "\n",
    "# Best estimators storage\n",
    "# Structure: {model_name: {dataset_type: best_estimator}}\n",
    "best_estimators = {\n",
    "    'SVC': {},\n",
    "    'MLP': {}\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EXTENDED STORAGE INITIALIZED\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Storage structures ready for:\")\n",
    "print(\"  - Centralized metrics table\")\n",
    "print(\"  - ROC probabilities (for Task 5)\")\n",
    "print(\"  - Best hyperparameters\")\n",
    "print(\"  - Best estimators\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee40493",
   "metadata": {},
   "source": [
    "## Step 5: SVC (RBF Kernel) Implementation\n",
    "\n",
    "Implement SVC with RBF kernel, GridSearchCV hyperparameter tuning, and store all metrics and probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db873ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING SVC (RBF KERNEL) MODELS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Training SVC on: Raw/Original\n",
      "======================================================================\n",
      "  Running GridSearchCV for SVC on Raw/Original dataset...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "  Best parameters: {'C': 100, 'gamma': 0.01}\n",
      "  Test Metrics - Accuracy: 0.8571, Precision: 0.5610, Recall: 0.4894, F1: 0.5227, ROC-AUC: 0.7786\n",
      "  Confusion Matrix - TN: 229, FP: 18, FN: 24, TP: 23\n",
      "\n",
      "======================================================================\n",
      "Training SVC on: SMOTE Balanced\n",
      "======================================================================\n",
      "  Running GridSearchCV for SVC on SMOTE Balanced dataset...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "  Best parameters: {'C': 10, 'gamma': 0.1}\n",
      "  Test Metrics - Accuracy: 0.8095, Precision: 0.3548, Recall: 0.2340, F1: 0.2821, ROC-AUC: 0.7339\n",
      "  Confusion Matrix - TN: 227, FP: 20, FN: 36, TP: 11\n",
      "\n",
      "======================================================================\n",
      "Training SVC on: ADASYN Balanced\n",
      "======================================================================\n",
      "  Running GridSearchCV for SVC on ADASYN Balanced dataset...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "  Best parameters: {'C': 10, 'gamma': 0.1}\n",
      "  Test Metrics - Accuracy: 0.8197, Precision: 0.4062, Recall: 0.2766, F1: 0.3291, ROC-AUC: 0.7405\n",
      "  Confusion Matrix - TN: 228, FP: 19, FN: 34, TP: 13\n",
      "\n",
      "======================================================================\n",
      "SVC TRAINING COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SVC (RBF Kernel) with GridSearchCV\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING SVC (RBF KERNEL) MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define hyperparameter grid for SVC\n",
    "svc_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Fixed parameters: RBF kernel and probability=True (required for predict_proba)\n",
    "svc_fixed_params = {\n",
    "    'kernel': 'rbf',\n",
    "    'probability': True  # Required for predict_proba and ROC curves\n",
    "}\n",
    "\n",
    "# Train SVC on each dataset\n",
    "for dataset_key in ['raw', 'smote', 'adasyn']:\n",
    "    dataset_name = training_sets[dataset_key]['name']\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training SVC on: {dataset_name}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Train model\n",
    "    result = train_model_with_gridsearch(\n",
    "        model_class=SVC,\n",
    "        param_grid=svc_param_grid,\n",
    "        X_train=training_sets[dataset_key]['X_train'],\n",
    "        y_train=training_sets[dataset_key]['y_train'],\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        model_name='SVC',\n",
    "        dataset_name=dataset_name,\n",
    "        **svc_fixed_params\n",
    "    )\n",
    "    \n",
    "    # Store best estimator\n",
    "    best_estimators['SVC'][dataset_key] = result['best_estimator']\n",
    "    \n",
    "    # Store best hyperparameters\n",
    "    best_hyperparameters['SVC'][dataset_key] = result['best_params']\n",
    "    \n",
    "    # Store ROC probabilities\n",
    "    roc_probabilities['SVC'][dataset_key] = {\n",
    "        'y_true': result['y_test'],\n",
    "        'y_score': result['y_test_prob']\n",
    "    }\n",
    "    \n",
    "    # Store metrics\n",
    "    all_metrics.append({\n",
    "        'model_name': 'SVC',\n",
    "        'dataset_type': dataset_key,\n",
    "        'accuracy': result['metrics']['accuracy'],\n",
    "        'precision_positive': result['metrics']['precision'],\n",
    "        'recall_positive': result['metrics']['recall'],\n",
    "        'f1_positive': result['metrics']['f1'],\n",
    "        'roc_auc': result['metrics']['roc_auc'],\n",
    "        'tn': result['metrics']['tn'],\n",
    "        'fp': result['metrics']['fp'],\n",
    "        'fn': result['metrics']['fn'],\n",
    "        'tp': result['metrics']['tp']\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SVC TRAINING COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5184111c",
   "metadata": {},
   "source": [
    "## Step 6: MLPClassifier (Neural Network) Implementation\n",
    "\n",
    "Implement MLPClassifier with GridSearchCV hyperparameter tuning, and store all metrics and probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1df6e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING MLPClassifier (NEURAL NETWORK) MODELS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Training MLPClassifier on: Raw/Original\n",
      "======================================================================\n",
      "  Running GridSearchCV for MLP on Raw/Original dataset...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "  Best parameters: {'alpha': 0.0001, 'hidden_layer_sizes': (100,)}\n",
      "  Test Metrics - Accuracy: 0.8571, Precision: 0.6923, Recall: 0.1915, F1: 0.3000, ROC-AUC: 0.7362\n",
      "  Confusion Matrix - TN: 243, FP: 4, FN: 38, TP: 9\n",
      "\n",
      "======================================================================\n",
      "Training MLPClassifier on: SMOTE Balanced\n",
      "======================================================================\n",
      "  Running GridSearchCV for MLP on SMOTE Balanced dataset...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "  Best parameters: {'alpha': 0.01, 'hidden_layer_sizes': (100, 50)}\n",
      "  Test Metrics - Accuracy: 0.7891, Precision: 0.3529, Recall: 0.3830, F1: 0.3673, ROC-AUC: 0.7196\n",
      "  Confusion Matrix - TN: 214, FP: 33, FN: 29, TP: 18\n",
      "\n",
      "======================================================================\n",
      "Training MLPClassifier on: ADASYN Balanced\n",
      "======================================================================\n",
      "  Running GridSearchCV for MLP on ADASYN Balanced dataset...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "  Best parameters: {'alpha': 0.01, 'hidden_layer_sizes': (100, 50)}\n",
      "  Test Metrics - Accuracy: 0.8299, Precision: 0.4615, Recall: 0.3830, F1: 0.4186, ROC-AUC: 0.7106\n",
      "  Confusion Matrix - TN: 226, FP: 21, FN: 29, TP: 18\n",
      "\n",
      "======================================================================\n",
      "MLPClassifier TRAINING COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MLPClassifier (Neural Network) with GridSearchCV\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING MLPClassifier (NEURAL NETWORK) MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define hyperparameter grid for MLPClassifier\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Fixed parameters: max_iter, random_state, early_stopping\n",
    "mlp_fixed_params = {\n",
    "    'max_iter': 500,\n",
    "    'random_state': 42,\n",
    "    'early_stopping': True\n",
    "}\n",
    "\n",
    "# Train MLPClassifier on each dataset\n",
    "for dataset_key in ['raw', 'smote', 'adasyn']:\n",
    "    dataset_name = training_sets[dataset_key]['name']\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training MLPClassifier on: {dataset_name}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Train model\n",
    "    result = train_model_with_gridsearch(\n",
    "        model_class=MLPClassifier,\n",
    "        param_grid=mlp_param_grid,\n",
    "        X_train=training_sets[dataset_key]['X_train'],\n",
    "        y_train=training_sets[dataset_key]['y_train'],\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        model_name='MLP',\n",
    "        dataset_name=dataset_name,\n",
    "        **mlp_fixed_params\n",
    "    )\n",
    "    \n",
    "    # Store best estimator\n",
    "    best_estimators['MLP'][dataset_key] = result['best_estimator']\n",
    "    \n",
    "    # Store best hyperparameters\n",
    "    best_hyperparameters['MLP'][dataset_key] = result['best_params']\n",
    "    \n",
    "    # Store ROC probabilities\n",
    "    roc_probabilities['MLP'][dataset_key] = {\n",
    "        'y_true': result['y_test'],\n",
    "        'y_score': result['y_test_prob']\n",
    "    }\n",
    "    \n",
    "    # Store metrics\n",
    "    all_metrics.append({\n",
    "        'model_name': 'MLP',\n",
    "        'dataset_type': dataset_key,\n",
    "        'accuracy': result['metrics']['accuracy'],\n",
    "        'precision_positive': result['metrics']['precision'],\n",
    "        'recall_positive': result['metrics']['recall'],\n",
    "        'f1_positive': result['metrics']['f1'],\n",
    "        'roc_auc': result['metrics']['roc_auc'],\n",
    "        'tn': result['metrics']['tn'],\n",
    "        'fp': result['metrics']['fp'],\n",
    "        'fn': result['metrics']['fn'],\n",
    "        'tp': result['metrics']['tp']\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MLPClassifier TRAINING COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b90aaa",
   "metadata": {},
   "source": [
    "## Step 7: Extended Metrics Table Display\n",
    "\n",
    "Display the comprehensive metrics table with all performance metrics and confusion matrix components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951af07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPREHENSIVE METRICS TABLE\n",
      "======================================================================\n",
      "\n",
      "--- Performance Metrics ---\n",
      "model_name         dataset  accuracy  precision_positive  recall_positive  f1_positive  roc_auc\n",
      "       SVC    Raw/Original  0.857143            0.560976         0.489362     0.522727 0.778620\n",
      "       SVC  SMOTE Balanced  0.809524            0.354839         0.234043     0.282051 0.733913\n",
      "       SVC ADASYN Balanced  0.819728            0.406250         0.276596     0.329114 0.740460\n",
      "       MLP    Raw/Original  0.857143            0.692308         0.191489     0.300000 0.736153\n",
      "       MLP  SMOTE Balanced  0.789116            0.352941         0.382979     0.367347 0.719614\n",
      "       MLP ADASYN Balanced  0.829932            0.461538         0.382979     0.418605 0.710569\n",
      "\n",
      "--- Confusion Matrix Components ---\n",
      "model_name         dataset  tn  fp  fn  tp\n",
      "       SVC    Raw/Original 229  18  24  23\n",
      "       SVC  SMOTE Balanced 227  20  36  11\n",
      "       SVC ADASYN Balanced 228  19  34  13\n",
      "       MLP    Raw/Original 243   4  38   9\n",
      "       MLP  SMOTE Balanced 214  33  29  18\n",
      "       MLP ADASYN Balanced 226  21  29  18\n",
      "\n",
      "--- Summary Statistics by Model ---\n",
      "           accuracy         precision_positive         recall_positive  \\\n",
      "               mean     std               mean     std            mean   \n",
      "model_name                                                               \n",
      "MLP          0.8254  0.0342             0.5023  0.1733          0.3191   \n",
      "SVC          0.8288  0.0251             0.4407  0.1073          0.3333   \n",
      "\n",
      "                   f1_positive         roc_auc          \n",
      "               std        mean     std    mean     std  \n",
      "model_name                                              \n",
      "MLP         0.1106       0.362  0.0595  0.7221  0.0130  \n",
      "SVC         0.1368       0.378  0.1276  0.7510  0.0241  \n",
      "\n",
      "--- Summary Statistics by Dataset ---\n",
      "                accuracy         precision_positive         recall_positive  \\\n",
      "                    mean     std               mean     std            mean   \n",
      "dataset                                                                       \n",
      "ADASYN Balanced   0.8248  0.0072             0.4339  0.0391          0.3298   \n",
      "Raw/Original      0.8571  0.0000             0.6266  0.0929          0.3404   \n",
      "SMOTE Balanced    0.7993  0.0144             0.3539  0.0013          0.3085   \n",
      "\n",
      "                        f1_positive         roc_auc          \n",
      "                    std        mean     std    mean     std  \n",
      "dataset                                                      \n",
      "ADASYN Balanced  0.0752      0.3739  0.0633  0.7255  0.0211  \n",
      "Raw/Original     0.2106      0.4114  0.1575  0.7574  0.0300  \n",
      "SMOTE Balanced   0.1053      0.3247  0.0603  0.7268  0.0101  \n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Extended Metrics Table Display\n",
    "# ============================================================\n",
    "\n",
    "if len(all_metrics) > 0:\n",
    "    # Convert to DataFrame\n",
    "    metrics_df = pd.DataFrame(all_metrics)\n",
    "    \n",
    "    # Map dataset_type to readable names\n",
    "    dataset_name_map = {\n",
    "        'raw': 'Raw/Original',\n",
    "        'smote': 'SMOTE Balanced',\n",
    "        'adasyn': 'ADASYN Balanced'\n",
    "    }\n",
    "    metrics_df['dataset'] = metrics_df['dataset_type'].map(dataset_name_map)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"COMPREHENSIVE METRICS TABLE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Display full table\n",
    "    display_cols = ['model_name', 'dataset', 'accuracy', 'precision_positive', \n",
    "                    'recall_positive', 'f1_positive', 'roc_auc']\n",
    "    print(\"\\n--- Performance Metrics ---\")\n",
    "    print(metrics_df[display_cols].to_string(index=False))\n",
    "    \n",
    "    # Display confusion matrix components\n",
    "    print(\"\\n--- Confusion Matrix Components ---\")\n",
    "    cm_cols = ['model_name', 'dataset', 'tn', 'fp', 'fn', 'tp']\n",
    "    print(metrics_df[cm_cols].to_string(index=False))\n",
    "    \n",
    "    # Summary statistics by model\n",
    "    print(\"\\n--- Summary Statistics by Model ---\")\n",
    "    summary_by_model = metrics_df.groupby('model_name').agg({\n",
    "        'accuracy': ['mean', 'std'],\n",
    "        'precision_positive': ['mean', 'std'],\n",
    "        'recall_positive': ['mean', 'std'],\n",
    "        'f1_positive': ['mean', 'std'],\n",
    "        'roc_auc': ['mean', 'std']\n",
    "    }).round(4)\n",
    "    print(summary_by_model)\n",
    "    \n",
    "    # Summary statistics by dataset\n",
    "    print(\"\\n--- Summary Statistics by Dataset ---\")\n",
    "    summary_by_dataset = metrics_df.groupby('dataset').agg({\n",
    "        'accuracy': ['mean', 'std'],\n",
    "        'precision_positive': ['mean', 'std'],\n",
    "        'recall_positive': ['mean', 'std'],\n",
    "        'f1_positive': ['mean', 'std'],\n",
    "        'roc_auc': ['mean', 'std']\n",
    "    }).round(4)\n",
    "    print(summary_by_dataset)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "else:\n",
    "    print(\"No metrics available yet. Please run model training cells first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6d66b6",
   "metadata": {},
   "source": [
    "## Step 8: ROC Probabilities Storage Summary\n",
    "\n",
    "Display the structure of stored ROC probabilities for Task 5 (ROC curve plotting).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb88baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ROC PROBABILITIES STORAGE\n",
      "======================================================================\n",
      "\n",
      "Structure: {model_name: {dataset_type: {'y_true': array, 'y_score': array}}}\n",
      "\n",
      "Stored probabilities for ROC curve plotting (Task 5):\n",
      "\n",
      "\n",
      "SVC:\n",
      "----------------------------------------------------------------------\n",
      "  Raw/Original:\n",
      "    y_true shape: (294,)\n",
      "    y_score shape: (294,)\n",
      "    y_true unique values: [0 1]\n",
      "    y_score range: [0.0125, 0.7770]\n",
      "  SMOTE Balanced:\n",
      "    y_true shape: (294,)\n",
      "    y_score shape: (294,)\n",
      "    y_true unique values: [0 1]\n",
      "    y_score range: [0.0000, 0.9874]\n",
      "  ADASYN Balanced:\n",
      "    y_true shape: (294,)\n",
      "    y_score shape: (294,)\n",
      "    y_true unique values: [0 1]\n",
      "    y_score range: [0.0000, 0.9903]\n",
      "\n",
      "MLP:\n",
      "----------------------------------------------------------------------\n",
      "  Raw/Original:\n",
      "    y_true shape: (294,)\n",
      "    y_score shape: (294,)\n",
      "    y_true unique values: [0 1]\n",
      "    y_score range: [0.0026, 0.6900]\n",
      "  SMOTE Balanced:\n",
      "    y_true shape: (294,)\n",
      "    y_score shape: (294,)\n",
      "    y_true unique values: [0 1]\n",
      "    y_score range: [0.0000, 0.9812]\n",
      "  ADASYN Balanced:\n",
      "    y_true shape: (294,)\n",
      "    y_score shape: (294,)\n",
      "    y_true unique values: [0 1]\n",
      "    y_score range: [0.0000, 0.9933]\n",
      "\n",
      "======================================================================\n",
      "All probabilities stored successfully for Task 5\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ROC Probabilities Storage Summary\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ROC PROBABILITIES STORAGE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nStructure: {model_name: {dataset_type: {'y_true': array, 'y_score': array}}}\")\n",
    "print(\"\\nStored probabilities for ROC curve plotting (Task 5):\\n\")\n",
    "\n",
    "for model_name in ['SVC', 'MLP']:\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(\"-\" * 70)\n",
    "    for dataset_key in ['raw', 'smote', 'adasyn']:\n",
    "        dataset_name = training_sets[dataset_key]['name']\n",
    "        if dataset_key in roc_probabilities[model_name]:\n",
    "            stored_data = roc_probabilities[model_name][dataset_key]\n",
    "            y_true = stored_data['y_true']\n",
    "            y_score = stored_data['y_score']\n",
    "            print(f\"  {dataset_name}:\")\n",
    "            print(f\"    y_true shape: {y_true.shape if hasattr(y_true, 'shape') else len(y_true)}\")\n",
    "            print(f\"    y_score shape: {y_score.shape if hasattr(y_score, 'shape') else len(y_score)}\")\n",
    "            print(f\"    y_true unique values: {np.unique(y_true)}\")\n",
    "            print(f\"    y_score range: [{y_score.min():.4f}, {y_score.max():.4f}]\")\n",
    "        else:\n",
    "            print(f\"  {dataset_name}: Not stored\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"All probabilities stored successfully for Task 5\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc81ff",
   "metadata": {},
   "source": [
    "## Step 9: Best Hyperparameters Storage\n",
    "\n",
    "Display the best hyperparameters for each model-dataset combination.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "309183db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BEST HYPERPARAMETERS\n",
      "======================================================================\n",
      "\n",
      "Structure: {model_name: {dataset_type: best_params_dict}}\n",
      "\n",
      "SVC:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  Raw/Original:\n",
      "    C: 100\n",
      "    gamma: 0.01\n",
      "\n",
      "  SMOTE Balanced:\n",
      "    C: 10\n",
      "    gamma: 0.1\n",
      "\n",
      "  ADASYN Balanced:\n",
      "    C: 10\n",
      "    gamma: 0.1\n",
      "\n",
      "MLP:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  Raw/Original:\n",
      "    alpha: 0.0001\n",
      "    hidden_layer_sizes: (100,)\n",
      "\n",
      "  SMOTE Balanced:\n",
      "    alpha: 0.01\n",
      "    hidden_layer_sizes: (100, 50)\n",
      "\n",
      "  ADASYN Balanced:\n",
      "    alpha: 0.01\n",
      "    hidden_layer_sizes: (100, 50)\n",
      "\n",
      "======================================================================\n",
      "All hyperparameters stored successfully\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Best Hyperparameters Storage\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BEST HYPERPARAMETERS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nStructure: {model_name: {dataset_type: best_params_dict}}\\n\")\n",
    "\n",
    "for model_name in ['SVC', 'MLP']:\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"-\" * 70)\n",
    "    for dataset_key in ['raw', 'smote', 'adasyn']:\n",
    "        dataset_name = training_sets[dataset_key]['name']\n",
    "        if dataset_key in best_hyperparameters[model_name]:\n",
    "            params = best_hyperparameters[model_name][dataset_key]\n",
    "            print(f\"\\n  {dataset_name}:\")\n",
    "            for param_name, param_value in params.items():\n",
    "                print(f\"    {param_name}: {param_value}\")\n",
    "        else:\n",
    "            print(f\"\\n  {dataset_name}: Not available\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"All hyperparameters stored successfully\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e24f2a",
   "metadata": {},
   "source": [
    "## Step 10: Best Estimators Storage Summary\n",
    "\n",
    "Display a summary of stored best estimators for each model-dataset combination.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5a67499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BEST ESTIMATORS STORAGE\n",
      "======================================================================\n",
      "\n",
      "Structure: {model_name: {dataset_type: best_estimator}}\n",
      "\n",
      "SVC:\n",
      "----------------------------------------------------------------------\n",
      "  Raw/Original:\n",
      "    Type: SVC\n",
      "    Parameters: {'C': 100, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': -1, 'probability': True, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "  SMOTE Balanced:\n",
      "    Type: SVC\n",
      "    Parameters: {'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': -1, 'probability': True, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "  ADASYN Balanced:\n",
      "    Type: SVC\n",
      "    Parameters: {'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': -1, 'probability': True, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "MLP:\n",
      "----------------------------------------------------------------------\n",
      "  Raw/Original:\n",
      "    Type: MLPClassifier\n",
      "    Parameters: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 500, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "  SMOTE Balanced:\n",
      "    Type: MLPClassifier\n",
      "    Parameters: {'activation': 'relu', 'alpha': 0.01, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 500, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "  ADASYN Balanced:\n",
      "    Type: MLPClassifier\n",
      "    Parameters: {'activation': 'relu', 'alpha': 0.01, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 500, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "======================================================================\n",
      "All best estimators stored successfully\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Best Estimators Storage Summary\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BEST ESTIMATORS STORAGE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nStructure: {model_name: {dataset_type: best_estimator}}\\n\")\n",
    "\n",
    "for model_name in ['SVC', 'MLP']:\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"-\" * 70)\n",
    "    for dataset_key in ['raw', 'smote', 'adasyn']:\n",
    "        dataset_name = training_sets[dataset_key]['name']\n",
    "        if dataset_key in best_estimators[model_name]:\n",
    "            estimator = best_estimators[model_name][dataset_key]\n",
    "            print(f\"  {dataset_name}:\")\n",
    "            print(f\"    Type: {type(estimator).__name__}\")\n",
    "            print(f\"    Parameters: {estimator.get_params()}\")\n",
    "        else:\n",
    "            print(f\"  {dataset_name}: Not available\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"All best estimators stored successfully\")\n",
    "print(\"=\" * 70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
